# -*- coding: utf-8 -*-
"""Logistic _Regression.ipnyb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z0iNUlNSJiew6oEPkzcN1AAlxZyMfI-_
"""

from sklearn import datasets
import numpy as np
iris = datasets.load_iris()
x = iris.data[:, :2]
y = (iris.target != 0) * 1

print(x.shape)
# print(x)
print(y.shape)
# print(y)
# print(len(x))

dataset = []

for i in range(len(x)):
  dataset.append([x[i], y[i]])

# for i in range(5):
#   print(dataset[i])

# A = np.array([1, dataset[0][0][0], dataset[0][0][1]])
# print(A)

import random

shuffled_data = dataset.copy()
random.shuffle(shuffled_data)

train_set = []
val_set = []
test_set = []

# Splitting dataset into train, validation and test set

for s in shuffled_data:
  num = random.random()
  if num >= 0 and num <= 0.7:
    train_set.append(s)
  elif num > 0.7 and num <= 0.85:
    val_set.append(s)
  else:
    test_set.append(s)

print('train set length:', len(train_set))
print('val set length:', len(val_set))
print('test set length:', len(test_set))

import math

def sigmoid(z):
  return 1/(1 + np.exp(-z))

# print(sigmoid(5))

def log(x):
  if x == 0:
    return float('-inf')
  else:
    return math.log(x)

def multiply(a, b):
  if a == 0:
    return 0
  else:
    return a*b

def logloss(y, h):
  a = multiply(-y, log(h))
  b = multiply((1-y), log(1-h))
  J = a - b
  return J

# print(logloss(1, 1))
# print(logloss(1, 0))
# print(logloss(0, 0))

# Training code

LR = 0.00001
train_loss = []
theta = []

for i in range(3):
  num = random.random()
  theta.append(num)

Theta = np.array(theta)

# print(Theta)

myrange = 1000

for i in range(myrange):
  TJ = 0
  for s in train_set:
    X = np.array([1, s[0][0], s[0][1]])
    Z = np.dot(X, Theta)
    h = sigmoid(Z)
    y = s[1]
    J = logloss(y, h)
    TJ += J
    dv = X*(h-y)
    Theta -= dv*LR
  TJ = TJ/len(train_set)
  train_loss.append(TJ)

last_TJ = train_loss[-1]
print(last_TJ)

import matplotlib.pyplot as plt

epoch = list(range(myrange))

plt.plot(epoch, train_loss)
plt.xlabel("Epoch")
plt.ylabel("Train loss")
# plt.show()

# validation code

correct = 0

for s in val_set:
  X = np.array([1, s[0][0], s[0][1]])
  Z = np.dot(X, Theta)
  h = sigmoid(Z)
  if h >= 0.5:
    h = 1
  else:
    h = 0
  if h == y:
    correct += 1

val_acc = (correct/len(val_set))*100

print(val_acc)

# test code

correct = 0

for s in test_set:
  X = np.array([1, s[0][0], s[0][1]])
  Z = np.dot(X, Theta)
  h = sigmoid(Z)
  if h >= 0.5:
    h = 1
  else:
    h = 0
  if h == y:
    correct += 1

val_acc = (correct/len(test_set))*100

print(val_acc)